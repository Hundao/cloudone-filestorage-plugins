import os
import json
from datetime import datetime
from urllib.parse import urlparse

import boto3


def get_bucket_name(file_url):

    url = urlparse(file_url)
    return url.hostname.split('.')[0]


def get_iso_str(ts):

    dt = datetime.fromtimestamp(ts)
    return dt.isoformat()


def fetch_account_name():

    account_client = boto3.client('account')
    response = account_client.get_alternate_contact(
        AlternateContactType='SECURITY'
    )

    return response['AlternateContact']['Name']


def divide_to_chunks(iterable_collection, size):

    for i in range(0, len(iterable_collection), size):
        yield iterable_collection[i:i + size]


def lambda_handler(event, context):

    target_sns_arn = os.environ['TARGET_SNS_ARN']

    scan_results = []
    account_name = fetch_account_name()

    for record in event['Records']:

        print('record', record)

        # Message details from SNS event
        message = json.loads(record['Sns']['Message'])
        findings = message['scanning_result'].get('Findings')

        if not findings:
            continue

        finding = findings[0]

        scan_results.append({
            'bucket_name': get_bucket_name(message['file_url']),
            'account_name': account_name,
            'malware': finding['malware'],
            'malware_type': finding['type'],
            'time': get_iso_str(message['timestamp'])
        })

    print('scan_results', scan_results)

    sns_client = boto3.client('sns')
    fails = []
    request_entries = [
        {
            'Message': json.dumps(scan_result),
            'Id': str(i)
        }
        for i, scan_result in enumerate(scan_results)
    ]

    for entries_chunk in divide_to_chunks(request_entries, 10):
        response = sns_client.publish_batch(
            TopicArn=target_sns_arn,
            PublishBatchRequestEntries=entries_chunk,
        )

        fails += response['Failed']

    if fails:
        print(fails)
